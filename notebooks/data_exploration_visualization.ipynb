{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "404e64cb-28d6-454f-ae1d-205a48e30122",
   "metadata": {},
   "source": [
    "# ERCOT Price and Weather Data Exploration and Visualization\n",
    "\n",
    "This script provides comprehensive exploration and visualization of ERCOT price\n",
    "and weather data to gain insights for forecasting models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ed416e-741c-4afd-8f77-783ed28aab7c",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e5bd2c4-c16a-4155-9f1a-0ad0fceace69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpx\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple, Optional, Union, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0c7154-9b69-4b27-a2f9-0985941f8ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcabb30a-e665-4777-85f2-cc7dc110737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e14d7b-9e7d-47ad-9781-fb26895942ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.ercot_price_data import ErcotPriceData\n",
    "from src.data.ercot_weather_data import ErcotWeatherData\n",
    "from src.utils.preprocessing import align_time_series, create_time_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ac4a4c-95f5-4112-9004-f2297b30c44a",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Let's load price and weather data for multiple locations in ERCOT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffcf7fe-10b8-46b3-95a5-e1fdd080e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date range - look at last 2 years of data\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=2*365)  # 2 years of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db2690b-744e-4638-9664-d35c475dd245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define price nodes and locations to explore\n",
    "price_nodes = ['HB_HOUSTON', 'HB_NORTH', 'HB_SOUTH', 'HB_WEST']\n",
    "locations = ['Houston', 'Dallas', 'San Antonio', 'Midland']\n",
    "\n",
    "# Load price data for all nodes\n",
    "price_data = {}\n",
    "for node in price_nodes:\n",
    "    price_data[node] = ErcotPriceData().load_data(\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        price_node=node,\n",
    "        resample_freq='H'  # Hourly data\n",
    "    )\n",
    "    print(f\"Loaded price data for {node}: {price_data[node].shape} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d7d599-8fe3-4de1-9630-e8b2deb36d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weather data for all locations\n",
    "weather_data = {}\n",
    "for location in locations:\n",
    "    weather_data[location] = ErcotWeatherData().load_data(\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        location=location,\n",
    "        resample_freq='H'  # Hourly data\n",
    "    )\n",
    "    print(f\"Loaded weather data for {location}: {weather_data[location].shape} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77b0044-4ea8-49ce-97d2-1133424f0045",
   "metadata": {},
   "source": [
    "## Basic Price Data Statistics\n",
    "\n",
    "Let's examine the statistics of price data across different ERCOT hubs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff35a8-31fe-4423-95d8-0e2e3e37d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary DataFrame of price statistics\n",
    "price_stats = pd.DataFrame()\n",
    "\n",
    "for node in price_nodes:\n",
    "    # Basic statistics\n",
    "    node_stats = {\n",
    "        'Mean': price_data[node]['price'].mean(),\n",
    "        'Median': price_data[node]['price'].median(),\n",
    "        'Std Dev': price_data[node]['price'].std(),\n",
    "        'Min': price_data[node]['price'].min(),\n",
    "        'Max': price_data[node]['price'].max(),\n",
    "        'Skew': price_data[node]['price'].skew(),\n",
    "        'Kurtosis': price_data[node]['price'].kurtosis(),\n",
    "        '95th Percentile': price_data[node]['price'].quantile(0.95),\n",
    "        '99th Percentile': price_data[node]['price'].quantile(0.99)\n",
    "    }\n",
    "    price_stats[node] = pd.Series(node_stats)\n",
    "\n",
    "print(\"Price Statistics Across ERCOT Hubs\")\n",
    "price_stats.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8e96f-8e7e-4977-9400-9261eeec47be",
   "metadata": {},
   "source": [
    "## Price Distribution Analysis\n",
    "\n",
    "Let's visualize the distribution of electricity prices across different hubs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e69b14-465a-49f9-9393-1d1f73c757a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with histograms for each node\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "for i, node in enumerate(price_nodes):\n",
    "    ax = fig.add_subplot(2, 2, i+1)\n",
    "    \n",
    "    # Plot histogram with KDE\n",
    "    sns.histplot(price_data[node]['price'], kde=True, bins=100, ax=ax)\n",
    "    \n",
    "    # Add vertical lines for mean and median\n",
    "    plt.axvline(price_data[node]['price'].mean(), color='r', linestyle='--', label='Mean')\n",
    "    plt.axvline(price_data[node]['price'].median(), color='g', linestyle='-.', label='Median')\n",
    "    \n",
    "    # Set title and labels\n",
    "    plt.title(f'{node} Price Distribution')\n",
    "    plt.xlabel('Price ($/MWh)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Limit x-axis to better visualize the distribution (excluding extreme outliers)\n",
    "    plt.xlim(0, price_data[node]['price'].quantile(0.99))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6bc44a-a5a0-4289-80dd-e4dcd27587bc",
   "metadata": {},
   "source": [
    "## Price Spike Analysis\n",
    "\n",
    "Let's analyze the frequency and magnitude of price spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e6221d-7520-4c49-8917-97473d73a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds for moderate and extreme price spikes\n",
    "moderate_threshold = 100  # $/MWh\n",
    "extreme_threshold = 300   # $/MWh\n",
    "\n",
    "# Calculate spike statistics\n",
    "spike_stats = pd.DataFrame()\n",
    "\n",
    "for node in price_nodes:\n",
    "    prices = price_data[node]['price']\n",
    "    \n",
    "    # Calculate spike metrics\n",
    "    moderate_spikes = (prices > moderate_threshold) & (prices <= extreme_threshold)\n",
    "    extreme_spikes = prices > extreme_threshold\n",
    "    \n",
    "    node_stats = {\n",
    "        'Moderate Spikes (%)': moderate_spikes.mean() * 100,\n",
    "        'Extreme Spikes (%)': extreme_spikes.mean() * 100,\n",
    "        'Max Spike ($/MWh)': prices.max(),\n",
    "        'Average Spike Duration (hours)': 0,  # Will calculate below\n",
    "        'Longest Spike Duration (hours)': 0   # Will calculate below\n",
    "    }\n",
    "    \n",
    "    # Calculate spike durations\n",
    "    in_spike = False\n",
    "    current_duration = 0\n",
    "    durations = []\n",
    "    \n",
    "    for is_spike in (moderate_spikes | extreme_spikes):\n",
    "        if is_spike:\n",
    "            in_spike = True\n",
    "            current_duration += 1\n",
    "        elif in_spike:\n",
    "            durations.append(current_duration)\n",
    "            in_spike = False\n",
    "            current_duration = 0\n",
    "    \n",
    "    # Add the last spike if we ended during one\n",
    "    if current_duration > 0:\n",
    "        durations.append(current_duration)\n",
    "    \n",
    "    # Update statistics\n",
    "    if durations:\n",
    "        node_stats['Average Spike Duration (hours)'] = np.mean(durations)\n",
    "        node_stats['Longest Spike Duration (hours)'] = np.max(durations)\n",
    "    \n",
    "    spike_stats[node] = pd.Series(node_stats)\n",
    "\n",
    "print(\"Price Spike Statistics Across ERCOT Hubs\")\n",
    "spike_stats.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de16d68f-151b-42f2-bcb9-ce00e8046d4a",
   "metadata": {},
   "source": [
    "## Time Series Visualization of Prices\n",
    "\n",
    "Let's visualize the price time series and identify patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8740bc17-e82d-4562-9ed7-2e0c214eb51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive plot with all price nodes\n",
    "fig = go.Figure()\n",
    "\n",
    "for node in price_nodes:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=price_data[node].index,\n",
    "        y=price_data[node]['price'],\n",
    "        mode='lines',\n",
    "        name=node\n",
    "    ))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='ERCOT Hub Prices',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Price ($/MWh)',\n",
    "    height=600,\n",
    "    width=1000,\n",
    "    template='plotly_white',\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)\n",
    ")\n",
    "\n",
    "# Limit y-axis to better visualize (excluding extreme outliers)\n",
    "y_max = max([price_data[node]['price'].quantile(0.99) for node in price_nodes])\n",
    "fig.update_yaxes(range=[0, y_max])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749e1c1f-91e9-43f5-9f1a-b5627cd7f8c4",
   "metadata": {},
   "source": [
    "## Price Volatility Analysis\n",
    "\n",
    "Let's analyze price volatility over time using rolling standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf4531-98a0-4371-b1d0-ff05c5aef688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling volatility (standard deviation) for different windows\n",
    "windows = [24, 168, 720]  # 1 day, 1 week, 1 month (in hours)\n",
    "window_labels = ['1-Day', '1-Week', '1-Month']\n",
    "\n",
    "# Create a figure with volatility plots for Houston hub\n",
    "fig = go.Figure()\n",
    "\n",
    "for window, label in zip(windows, window_labels):\n",
    "    volatility = price_data['HB_HOUSTON']['price'].rolling(window=window).std()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=price_data['HB_HOUSTON'].index,\n",
    "        y=volatility,\n",
    "        mode='lines',\n",
    "        name=f'{label} Volatility'\n",
    "    ))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='ERCOT Houston Hub Price Volatility',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Price Volatility ($/MWh)',\n",
    "    height=500,\n",
    "    width=1000,\n",
    "    template='plotly_white',\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14ed330-4616-4925-a457-78c9461721cb",
   "metadata": {},
   "source": [
    "## Seasonal and Temporal Patterns\n",
    "\n",
    "Let's explore seasonal and temporal patterns in electricity prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cffd4c4-9e98-4477-ae47-dfec021e7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align price and weather data for Houston\n",
    "houston_data = align_time_series(price_data['HB_HOUSTON'], weather_data['Houston'])\n",
    "\n",
    "# Add time features\n",
    "houston_data = create_time_features(houston_data)\n",
    "\n",
    "# Group by month and hour to create a heatmap of average prices\n",
    "monthly_hourly_avg = houston_data.groupby(['month', 'hour'])['price'].mean().unstack()\n",
    "\n",
    "# Create a heatmap of hourly prices by month\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(monthly_hourly_avg, cmap='viridis', annot=False, fmt='.1f')\n",
    "plt.title('Average Hourly Prices by Month (Houston Hub)')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Month')\n",
    "plt.show()\n",
    "\n",
    "# Create seasonal aggregations\n",
    "seasons = {\n",
    "    'Winter': [12, 1, 2],\n",
    "    'Spring': [3, 4, 5],\n",
    "    'Summer': [6, 7, 8],\n",
    "    'Fall': [9, 10, 11]\n",
    "}\n",
    "\n",
    "# Create a DataFrame for seasonal hourly patterns\n",
    "seasonal_hourly = pd.DataFrame()\n",
    "\n",
    "for season, months in seasons.items():\n",
    "    seasonal_data = houston_data[houston_data['month'].isin(months)]\n",
    "    hourly_avg = seasonal_data.groupby('hour')['price'].mean()\n",
    "    seasonal_hourly[season] = hourly_avg\n",
    "\n",
    "# Plot seasonal hourly patterns\n",
    "plt.figure(figsize=(14, 8))\n",
    "for season in seasonal_hourly.columns:\n",
    "    plt.plot(seasonal_hourly.index, seasonal_hourly[season], label=season, linewidth=3)\n",
    "\n",
    "plt.title('Hourly Price Patterns by Season (Houston Hub)')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Average Price ($/MWh)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f32acfd-ab55-4914-a054-6f266ac8fb0e",
   "metadata": {},
   "source": [
    "## Correlation Between Hubs\n",
    "\n",
    "Let's analyze the correlations between different ERCOT hubs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d7fc66-af09-4248-a1e7-eae8d3f17ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with all hub prices\n",
    "all_prices = pd.DataFrame()\n",
    "for node in price_nodes:\n",
    "    all_prices[node] = price_data[node]['price']\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = all_prices.corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, linewidths=.5)\n",
    "plt.title('Price Correlation Between ERCOT Hubs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a66654d-5823-4e6b-9d29-b3b8c205e4d3",
   "metadata": {},
   "source": [
    "## Weather Data Exploration\n",
    " \n",
    "Let's explore the weather data for different locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e1e42-3a8d-4147-bfaa-103992aeb30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary DataFrame of weather statistics for Houston\n",
    "weather_vars = ['temperature', 'wind_speed', 'solar_irradiance', 'humidity']\n",
    "houston_weather = weather_data['Houston']\n",
    "\n",
    "weather_stats = pd.DataFrame()\n",
    "for var in weather_vars:\n",
    "    var_stats = {\n",
    "        'Mean': houston_weather[var].mean(),\n",
    "        'Median': houston_weather[var].median(),\n",
    "        'Std Dev': houston_weather[var].std(),\n",
    "        'Min': houston_weather[var].min(),\n",
    "        'Max': houston_weather[var].max()\n",
    "    }\n",
    "    weather_stats[var] = pd.Series(var_stats)\n",
    "\n",
    "print(\"Weather Statistics for Houston\")\n",
    "weather_stats.T\n",
    "\n",
    "# Plot distributions of weather variables\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "for i, var in enumerate(weather_vars):\n",
    "    ax = fig.add_subplot(2, 2, i+1)\n",
    "    \n",
    "    # Plot histogram with KDE\n",
    "    sns.histplot(houston_weather[var], kde=True, bins=50, ax=ax)\n",
    "    \n",
    "    # Add vertical lines for mean and median\n",
    "    plt.axvline(houston_weather[var].mean(), color='r', linestyle='--', label='Mean')\n",
    "    plt.axvline(houston_weather[var].median(), color='g', linestyle='-.', label='Median')\n",
    "    \n",
    "    # Set title and labels\n",
    "    plt.title(f'Houston {var.capitalize()} Distribution')\n",
    "    plt.xlabel(var.capitalize())\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2439c225-644e-4886-8edd-2551c96f5cf0",
   "metadata": {},
   "source": [
    "## Seasonal Weather Patterns\n",
    "\n",
    "Let's analyze seasonal patterns in weather variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36650aed-135d-403d-ba64-14a34628554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create monthly averages for each weather variable in Houston\n",
    "monthly_weather = pd.DataFrame()\n",
    "\n",
    "for var in weather_vars:\n",
    "    monthly_weather[var] = houston_weather.groupby(houston_weather.index.month)[var].mean()\n",
    "\n",
    "# Plot monthly weather patterns\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "for i, var in enumerate(weather_vars):\n",
    "    ax = fig.add_subplot(2, 2, i+1)\n",
    "    \n",
    "    # Plot monthly average\n",
    "    months = range(1, 13)\n",
    "    month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    \n",
    "    plt.bar(months, monthly_weather[var])\n",
    "    plt.xticks(months, month_names)\n",
    "    \n",
    "    # Set title and labels\n",
    "    plt.title(f'Monthly Average {var.capitalize()} in Houston')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel(var.capitalize())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e0d738-9b1d-485b-835e-ce8357b032a7",
   "metadata": {},
   "source": [
    "## Price vs. Weather Analysis\n",
    "\n",
    "Let's analyze the relationship between price and weather variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c8699-470c-42cd-aef4-3b8c01ae1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aligned data for Houston\n",
    "# Create scatter plots for each weather variable vs. price\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "for i, var in enumerate(weather_vars):\n",
    "    ax = fig.add_subplot(2, 2, i+1)\n",
    "    \n",
    "    # Plot scatter with trend line\n",
    "    sns.regplot(x=houston_data[var], y=houston_data['price'], scatter_kws={'alpha': 0.3}, line_kws={'color': 'red'}, ax=ax)\n",
    "    \n",
    "    # Set title and labels\n",
    "    plt.title(f'Price vs. {var.capitalize()}')\n",
    "    plt.xlabel(var.capitalize())\n",
    "    plt.ylabel('Price ($/MWh)')\n",
    "    \n",
    "    # Limit y-axis to better visualize (excluding extreme outliers)\n",
    "    plt.ylim(0, houston_data['price'].quantile(0.99))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation matrix for Houston price and weather\n",
    "corr_matrix = houston_data[['price'] + weather_vars].corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, linewidths=.5)\n",
    "plt.title('Correlation: Price vs. Weather Variables (Houston)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d95888-9225-48f7-8e02-34f52b89d4e8",
   "metadata": {},
   "source": [
    "## Price vs. Weather by Season\n",
    "\n",
    "Let's analyze how the relationship between price and weather varies by season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4324a6eb-e19e-4ec3-b6d8-174e60dcddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create seasonal data for Houston\n",
    "seasonal_data = {}\n",
    "for season, months in seasons.items():\n",
    "    seasonal_data[season] = houston_data[houston_data['month'].isin(months)]\n",
    "\n",
    "# Plot the relationship between temperature and price for each season\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for season, data in seasonal_data.items():\n",
    "    plt.scatter(data['temperature'], data['price'], alpha=0.3, label=season)\n",
    "\n",
    "plt.title('Price vs. Temperature by Season (Houston)')\n",
    "plt.xlabel('Temperature (Â°C)')\n",
    "plt.ylabel('Price ($/MWh)')\n",
    "plt.ylim(0, houston_data['price'].quantile(0.99))\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate seasonal correlations between price and weather\n",
    "seasonal_corr = {}\n",
    "for season, data in seasonal_data.items():\n",
    "    seasonal_corr[season] = data[['price'] + weather_vars].corr()['price'].drop('price')\n",
    "\n",
    "# Create a DataFrame with seasonal correlations\n",
    "seasonal_corr_df = pd.DataFrame(seasonal_corr)\n",
    "seasonal_corr_df\n",
    "\n",
    "# Plot seasonal correlations as a bar chart\n",
    "seasonal_corr_df.plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Seasonal Correlation: Price vs. Weather Variables (Houston)')\n",
    "plt.xlabel('Weather Variable')\n",
    "plt.ylabel('Correlation with Price')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b17303-feb3-488e-9e4e-0bc08a0f11f5",
   "metadata": {},
   "source": [
    "## Extreme Weather Impact Analysis\n",
    "\n",
    "Let's analyze how extreme weather conditions impact electricity prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c119bd1-1186-4f93-a27e-3baa8ee096b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds for extreme weather conditions in Houston\n",
    "extreme_conditions = {\n",
    "    'High Temperature': houston_weather['temperature'] > houston_weather['temperature'].quantile(0.95),\n",
    "    'Low Temperature': houston_weather['temperature'] < houston_weather['temperature'].quantile(0.05),\n",
    "    'High Wind': houston_weather['wind_speed'] > houston_weather['wind_speed'].quantile(0.95),\n",
    "    'Low Solar': houston_weather['solar_irradiance'] < houston_weather['solar_irradiance'].quantile(0.05),\n",
    "    'High Humidity': houston_weather['humidity'] > houston_weather['humidity'].quantile(0.95)\n",
    "}\n",
    "\n",
    "# Create an aligned price series\n",
    "aligned_price = align_time_series(price_data['HB_HOUSTON'], houston_weather)['price']\n",
    "\n",
    "# Calculate average prices during extreme conditions vs. normal conditions\n",
    "extreme_price_impact = pd.DataFrame(columns=['Avg Price ($)', 'Price Increase (%)', 'Volatility Increase (%)'])\n",
    "\n",
    "normal_price_avg = aligned_price.mean()\n",
    "normal_price_vol = aligned_price.std()\n",
    "\n",
    "for condition, mask in extreme_conditions.items():\n",
    "    extreme_price = aligned_price[mask]\n",
    "    extreme_price_avg = extreme_price.mean()\n",
    "    extreme_price_vol = extreme_price.std()\n",
    "    \n",
    "    price_increase = (extreme_price_avg / normal_price_avg - 1) * 100\n",
    "    vol_increase = (extreme_price_vol / normal_price_vol - 1) * 100\n",
    "    \n",
    "    extreme_price_impact.loc[condition] = [\n",
    "        extreme_price_avg,\n",
    "        price_increase,\n",
    "        vol_increase\n",
    "    ]\n",
    "\n",
    "print(\"Impact of Extreme Weather Conditions on Houston Hub Prices\")\n",
    "extreme_price_impact\n",
    "\n",
    "# Create a bar chart comparing price increases during extreme conditions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(extreme_price_impact.index, extreme_price_impact['Price Increase (%)'])\n",
    "plt.title('Price Increase During Extreme Weather Conditions (Houston)')\n",
    "plt.xlabel('Weather Condition')\n",
    "plt.ylabel('Price Increase (%)')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336e3557-47ff-4e5a-ab16-a9dc5d7f4e7a",
   "metadata": {},
   "source": [
    "## Price Autocorrelation Analysis\n",
    "\n",
    "Let's analyze the autocorrelation of electricity prices to identify patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337779d-9eef-4f40-9b9f-c990c5b6c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate autocorrelation for Houston prices\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "# Create autocorrelation plot for Houston hub\n",
    "plt.figure(figsize=(12, 6))\n",
    "autocorrelation_plot(price_data['HB_HOUSTON']['price'])\n",
    "plt.title('Autocorrelation Plot for Houston Hub Prices')\n",
    "plt.xlim(0, 168*2)  # Limit to 2 weeks (in hours)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot autocorrelation with confidence intervals\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# ACF plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plot_acf(price_data['HB_HOUSTON']['price'], lags=168, alpha=0.05)  # One week of lags\n",
    "plt.title('Autocorrelation Function for Houston Hub Prices')\n",
    "plt.xlabel('Lag (hours)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# PACF plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plot_pacf(price_data['HB_HOUSTON']['price'], lags=48, alpha=0.05)  # Two days of lags\n",
    "plt.title('Partial Autocorrelation Function for Houston Hub Prices')\n",
    "plt.xlabel('Lag (hours)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890f08c1-c66b-43ce-b55e-36d0e7deec6d",
   "metadata": {},
   "source": [
    "## Cross-Correlation Between Weather and Price\n",
    "\n",
    "Let's analyze the cross-correlation between weather variables and electricity prices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5512cd6-a5f9-44d6-abff-513561cf7d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "# Calculate cross-correlation between temperature and price\n",
    "# First, align the series\n",
    "aligned_data = align_time_series(price_data['HB_HOUSTON'], weather_data['Houston'])\n",
    "price_series = aligned_data['price']\n",
    "temp_series = aligned_data['temperature']\n",
    "\n",
    "# Remove any NaN values\n",
    "valid_data = aligned_data.dropna()\n",
    "price_series = valid_data['price']\n",
    "temp_series = valid_data['temperature']\n",
    "\n",
    "# Calculate cross-correlation\n",
    "max_lag = 168  # One week in hours\n",
    "xcorr = signal.correlate(price_series - price_series.mean(), \n",
    "                         temp_series - temp_series.mean(), \n",
    "                         mode='full') / (len(price_series) * price_series.std() * temp_series.std())\n",
    "\n",
    "# Calculate lag array\n",
    "lags = np.arange(-max_lag, max_lag + 1)\n",
    "xcorr = xcorr[len(xcorr)//2 - max_lag:len(xcorr)//2 + max_lag + 1]\n",
    "\n",
    "# Plot cross-correlation\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(lags, xcorr)\n",
    "plt.title('Cross-Correlation: Temperature vs. Price (Houston)')\n",
    "plt.xlabel('Lag (hours)')\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.grid(True)\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "\n",
    "# Find the lag with maximum correlation\n",
    "max_corr_lag = lags[np.argmax(np.abs(xcorr))]\n",
    "plt.axvline(x=max_corr_lag, color='g', linestyle='--', \n",
    "            label=f'Max at lag={max_corr_lag} hours')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fddc9c7-de80-4ecd-bc30-71e1e89e9902",
   "metadata": {},
   "source": [
    "## Price Return Analysis\n",
    "\n",
    "Let's analyze price returns (percentage changes) to understand volatility patterns.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab1ac6b-ffb1-4aa9-a0a5-e07c4420fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hourly returns for all hubs\n",
    "returns = pd.DataFrame()\n",
    "\n",
    "for node in price_nodes:\n",
    "    # Calculate percentage returns\n",
    "    price_series = price_data[node]['price']\n",
    "    returns[node] = price_series.pct_change() * 100  # Convert to percentage\n",
    "\n",
    "# Remove extreme outliers for better visualization\n",
    "for node in price_nodes:\n",
    "    q1 = returns[node].quantile(0.01)\n",
    "    q99 = returns[node].quantile(0.99)\n",
    "    returns[node] = returns[node].clip(q1, q99)\n",
    "\n",
    "# Plot return distributions\n",
    "plt.figure(figsize=(12, 8))\n",
    "for node in price_nodes:\n",
    "    sns.kdeplot(returns[node].dropna(), label=node)\n",
    "\n",
    "plt.title('Distribution of Hourly Price Returns')\n",
    "plt.xlabel('Hourly Return (%)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display return statistics\n",
    "return_stats = pd.DataFrame()\n",
    "\n",
    "for node in price_nodes:\n",
    "    node_stats = {\n",
    "        'Mean Return (%)': returns[node].mean(),\n",
    "        'Std Dev (%)': returns[node].std(),\n",
    "        'Skewness': returns[node].skew(),\n",
    "        'Kurtosis': returns[node].kurtosis(),\n",
    "        'Positive Returns (%)': (returns[node] > 0).mean() * 100\n",
    "    }\n",
    "    return_stats[node] = pd.Series(node_stats)\n",
    "\n",
    "print(\"Hourly Return Statistics Across ERCOT Hubs\")\n",
    "return_stats.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283a603d-ea3f-41cf-803f-327bd9fecf95",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This exploratory data analysis has provided valuable insights into:\n",
    "\n",
    "1. The statistical properties of ERCOT electricity prices\n",
    "2. The frequency and magnitude of price spikes\n",
    "3. Seasonal and temporal patterns in prices\n",
    "4. Correlations between different ERCOT hubs\n",
    "5. The relationship between weather variables and prices\n",
    "6. Autocorrelation and cross-correlation patterns\n",
    "7. Price return characteristics\n",
    "\n",
    "These insights are essential for developing effective forecasting models and understanding the drivers of ERCOT electricity prices. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
