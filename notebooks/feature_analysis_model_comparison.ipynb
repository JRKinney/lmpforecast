{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aa794b7-a575-4a88-a439-b134412eff8d",
   "metadata": {},
   "source": [
    "# ERCOT Price Forecasting Feature Analysis and Model Comparison\n",
    "\n",
    "This script demonstrates how to analyze features that impact ERCOT electricity prices\n",
    "and compares different model configurations to find the optimal setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eafb3537-8451-4e68-8a1c-90833b66efd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandera' has no attribute 'SchemaModel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mggplot\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mercot_price_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ErcotPriceData\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mercot_weather_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ErcotWeatherData\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhybrid_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HybridModel\n",
      "File \u001b[0;32m~/projects/energy_projects/ercot_price_forecasting/src/data/ercot_price_data.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional, Union, List, Dict, Any\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandera\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschemas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PriceDataSchema, validate_dataframe\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mErcotPriceData\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    Class for loading and preprocessing ERCOT price data.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    - Apply transformations for analysis and modeling\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/energy_projects/ercot_price_forecasting/src/utils/schemas.py:16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandera\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Series, DataFrame, Index\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Schema for price data\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPriceDataSchema\u001b[39;00m(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSchemaModel\u001b[49m):\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    Schema for ERCOT price data.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    - Index is a datetime index\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Price column (must be non-negative)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandera' has no attribute 'SchemaModel'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple, Optional, Union, Any\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Add the project directory to the path so we can import modules\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "from src.data.ercot_price_data import ErcotPriceData\n",
    "from src.data.ercot_weather_data import ErcotWeatherData\n",
    "from src.models.hybrid_model import HybridModel\n",
    "from src.utils.preprocessing import (\n",
    "    align_time_series,\n",
    "    create_time_features,\n",
    "    create_lag_features,\n",
    "    create_rolling_features,\n",
    "    prepare_data_for_model\n",
    ")\n",
    "from src.visualization.plotting import (\n",
    "    plot_price_forecast,\n",
    "    plot_volatility_forecast,\n",
    "    plot_price_components,\n",
    "    plot_model_performance\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0f7983-3ffe-42a1-84ee-982c5903f842",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation\n",
    "\n",
    "First, let's load the price and weather data for multiple ERCOT hubs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eed0fe-8dd7-4610-a2cf-a82fa74a811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date range for our analysis\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=365)  # Use one year of data\n",
    "test_start_date = end_date - timedelta(days=30)  # Last 30 days for testing\n",
    "\n",
    "# Define the price nodes to analyze\n",
    "price_nodes = ['HB_HOUSTON', 'HB_NORTH', 'HB_SOUTH', 'HB_WEST']\n",
    "locations = ['Houston', 'Dallas', 'San Antonio', 'Midland']\n",
    "\n",
    "# Create empty dictionaries to store data for each node\n",
    "price_data_dict = {}\n",
    "weather_data_dict = {}\n",
    "\n",
    "# Load price and weather data for each node/location\n",
    "for node, location in zip(price_nodes, locations):\n",
    "    # Load price data\n",
    "    price_data_dict[node] = ErcotPriceData().load_data(\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        price_node=node,\n",
    "        resample_freq='H'\n",
    "    )\n",
    "    \n",
    "    # Load weather data\n",
    "    weather_data_dict[location] = ErcotWeatherData().load_data(\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        location=location,\n",
    "        resample_freq='H'\n",
    "    )\n",
    "    \n",
    "    print(f\"Loaded data for {node} / {location}\")\n",
    "    print(f\"  Price data shape: {price_data_dict[node].shape}\")\n",
    "    print(f\"  Weather data shape: {weather_data_dict[location].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8e4fbe-bb64-44bf-9749-37005ac05d17",
   "metadata": {},
   "source": [
    "## Price Comparison Across ERCOT Hubs\n",
    "\n",
    "Let's compare price patterns across different ERCOT hubs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09442f5e-ce63-4065-ad16-0b033526eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with prices from all nodes\n",
    "all_prices = pd.DataFrame()\n",
    "for node in price_nodes:\n",
    "    all_prices[node] = price_data_dict[node]['price']\n",
    "\n",
    "# Plot price comparison\n",
    "fig = go.Figure()\n",
    "\n",
    "for node in price_nodes:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=all_prices.index,\n",
    "        y=all_prices[node],\n",
    "        mode='lines',\n",
    "        name=node\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='ERCOT Price Comparison Across Hubs',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Price ($/MWh)',\n",
    "    height=600,\n",
    "    width=1000,\n",
    "    template='plotly_white',\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Calculate correlation between prices at different hubs\n",
    "price_correlation = all_prices.corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "fig_corr = px.imshow(\n",
    "    price_correlation,\n",
    "    text_auto=True,\n",
    "    color_continuous_scale='RdBu_r',\n",
    "    title='Price Correlation Across ERCOT Hubs',\n",
    "    height=500,\n",
    "    width=700\n",
    ")\n",
    "fig_corr.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d95a68-8060-47d5-81ac-1e5aca5919d5",
   "metadata": {},
   "source": [
    "## Feature Engineering and Analysis\n",
    "\n",
    "Let's analyze features for predicting electricity prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260af215-1a71-43ef-85b8-836bbe551e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Houston hub for feature analysis\n",
    "hub = 'HB_HOUSTON'\n",
    "location = 'Houston'\n",
    "price_data = price_data_dict[hub]\n",
    "weather_data = weather_data_dict[location]\n",
    "\n",
    "# Align and preprocess data\n",
    "preprocessed_data = align_time_series(price_data, weather_data)\n",
    "preprocessed_data = create_time_features(preprocessed_data)\n",
    "preprocessed_data = create_lag_features(\n",
    "    preprocessed_data, \n",
    "    target_column='price', \n",
    "    lag_periods=[1, 2, 3, 6, 12, 24, 48, 72, 168]  # Multiple lag periods for analysis\n",
    ")\n",
    "preprocessed_data = create_rolling_features(\n",
    "    preprocessed_data, \n",
    "    target_column='price',\n",
    "    windows=[24, 48, 72, 168],  # Multiple windows for analysis\n",
    "    functions=['mean', 'std', 'min', 'max']  # Additional statistical features\n",
    ")\n",
    "\n",
    "# Drop NaN values\n",
    "preprocessed_data = preprocessed_data.dropna()\n",
    "print(f\"Preprocessed data shape: {preprocessed_data.shape}\")\n",
    "print(f\"Number of features: {preprocessed_data.shape[1] - 1}\")  # Excluding price column\n",
    "\n",
    "# Split into features and target\n",
    "X = preprocessed_data.drop('price', axis=1)\n",
    "y = preprocessed_data['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3750d38-802a-48f4-8be1-727646014ae6",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis\n",
    "\n",
    "Let's calculate feature importance using mutual information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ed9c6-3905-41b5-bd13-019645460db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mutual information between each feature and the price\n",
    "mi_scores = mutual_info_regression(X, y)\n",
    "mi_df = pd.DataFrame({'Feature': X.columns, 'MI Score': mi_scores})\n",
    "mi_df = mi_df.sort_values('MI Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display top 20 features\n",
    "print(\"Top 20 features by mutual information:\")\n",
    "print(mi_df.head(20))\n",
    "\n",
    "# Plot feature importance\n",
    "fig = px.bar(\n",
    "    mi_df.head(20),\n",
    "    x='MI Score',\n",
    "    y='Feature',\n",
    "    orientation='h',\n",
    "    title='Feature Importance by Mutual Information',\n",
    "    height=600,\n",
    "    width=900\n",
    ")\n",
    "fig.update_layout(yaxis={'categoryorder': 'total ascending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e235d-11ed-475f-b12c-2961b1a9bd3d",
   "metadata": {},
   "source": [
    "## Feature Correlation Analysis\n",
    "\n",
    "Let's analyze correlation between features and price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a29404-f653-4e14-8c40-0cbdc6bfeec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation with price\n",
    "corr_with_price = preprocessed_data.corr()['price'].drop('price')\n",
    "corr_df = pd.DataFrame({'Feature': corr_with_price.index, 'Correlation': corr_with_price.values})\n",
    "corr_df = corr_df.sort_values('Correlation', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display top positive and negative correlations\n",
    "print(\"Top 10 features with positive correlation:\")\n",
    "print(corr_df.head(10))\n",
    "print(\"\\nTop 10 features with negative correlation:\")\n",
    "print(corr_df.tail(10))\n",
    "\n",
    "# Plot correlations\n",
    "fig = px.bar(\n",
    "    pd.concat([corr_df.head(10), corr_df.tail(10)]).sort_values('Correlation'),\n",
    "    x='Correlation',\n",
    "    y='Feature',\n",
    "    orientation='h',\n",
    "    title='Feature Correlation with Price',\n",
    "    color='Correlation',\n",
    "    color_continuous_scale='RdBu_r',\n",
    "    height=600,\n",
    "    width=900\n",
    ")\n",
    "fig.update_layout(yaxis={'categoryorder': 'total ascending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81d5069-ab13-475f-bf9b-b60605667a58",
   "metadata": {},
   "source": [
    "## Time-Based Feature Analysis\n",
    "\n",
    "Let's analyze how price patterns vary by time of day, day of week, and month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d55ad-5584-499c-85fd-0ee8bcfbda15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-based aggregations\n",
    "hourly_avg = preprocessed_data.groupby('hour')['price'].mean()\n",
    "daily_avg = preprocessed_data.groupby('day_of_week')['price'].mean()\n",
    "monthly_avg = preprocessed_data.groupby('month')['price'].mean()\n",
    "\n",
    "# Plot hourly price patterns\n",
    "fig_hourly = px.line(\n",
    "    x=hourly_avg.index,\n",
    "    y=hourly_avg.values,\n",
    "    title='Average Price by Hour of Day',\n",
    "    labels={'x': 'Hour of Day', 'y': 'Average Price ($/MWh)'},\n",
    "    height=400,\n",
    "    width=800\n",
    ")\n",
    "fig_hourly.update_layout(template='plotly_white')\n",
    "fig_hourly.show()\n",
    "\n",
    "# Plot daily price patterns\n",
    "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "fig_daily = px.bar(\n",
    "    x=days,\n",
    "    y=[daily_avg.get(i, 0) for i in range(7)],\n",
    "    title='Average Price by Day of Week',\n",
    "    labels={'x': 'Day of Week', 'y': 'Average Price ($/MWh)'},\n",
    "    height=400,\n",
    "    width=800\n",
    ")\n",
    "fig_daily.update_layout(template='plotly_white')\n",
    "fig_daily.show()\n",
    "\n",
    "# Plot monthly price patterns\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "fig_monthly = px.bar(\n",
    "    x=months,\n",
    "    y=[monthly_avg.get(i+1, 0) for i in range(12)],\n",
    "    title='Average Price by Month',\n",
    "    labels={'x': 'Month', 'y': 'Average Price ($/MWh)'},\n",
    "    height=400,\n",
    "    width=800\n",
    ")\n",
    "fig_monthly.update_layout(template='plotly_white')\n",
    "fig_monthly.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde5dd4-1afe-449a-81b7-b004f623ca9f",
   "metadata": {},
   "source": [
    "## Weather Impact Analysis\n",
    "\n",
    "Let's analyze how weather variables impact electricity prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaefa06-c228-4a34-b0fd-ad0f178ef6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key weather variables\n",
    "weather_vars = ['temperature', 'wind_speed', 'solar_irradiance', 'humidity']\n",
    "\n",
    "# Create scatter plots for each weather variable\n",
    "for var in weather_vars:\n",
    "    fig = px.scatter(\n",
    "        preprocessed_data,\n",
    "        x=var,\n",
    "        y='price',\n",
    "        title=f'Price vs {var.capitalize()}',\n",
    "        trendline='ols',  # Add trend line\n",
    "        opacity=0.5,\n",
    "        height=500,\n",
    "        width=800\n",
    "    )\n",
    "    fig.update_layout(template='plotly_white')\n",
    "    fig.show()\n",
    "\n",
    "# Calculate correlation matrix for weather variables and price\n",
    "weather_price_corr = preprocessed_data[weather_vars + ['price']].corr()\n",
    "fig_corr = px.imshow(\n",
    "    weather_price_corr,\n",
    "    text_auto=True,\n",
    "    color_continuous_scale='RdBu_r',\n",
    "    title='Correlation: Weather Variables and Price',\n",
    "    height=500,\n",
    "    width=700\n",
    ")\n",
    "fig_corr.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30897a88-0a2c-4126-b2a5-4aa0611db8fe",
   "metadata": {},
   "source": [
    "## Model Hyperparameter Comparison\n",
    "\n",
    "Let's compare different hyperparameter configurations for our hybrid model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f2fe9d-71f6-48e4-a6de-7863179d8bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter combinations to test\n",
    "seq_lengths = [24, 48, 72]\n",
    "forecast_horizons = [12, 24]\n",
    "garch_p_values = [1, 2]\n",
    "garch_q_values = [1, 2]\n",
    "\n",
    "# Prepare data for model training/evaluation\n",
    "train_data = preprocessed_data[preprocessed_data.index < test_start_date]\n",
    "test_data = preprocessed_data[preprocessed_data.index >= test_start_date]\n",
    "\n",
    "train_price = train_data[['price']]\n",
    "test_price = test_data[['price']]\n",
    "\n",
    "feature_columns = [col for col in train_data.columns if col != 'price']\n",
    "train_features = train_data[feature_columns]\n",
    "test_features = test_data[feature_columns]\n",
    "\n",
    "# Initialize results tracking\n",
    "results = []\n",
    "\n",
    "# Train and evaluate models with different hyperparameters\n",
    "for seq_length in seq_lengths:\n",
    "    for forecast_horizon in forecast_horizons:\n",
    "        for p in garch_p_values:\n",
    "            for q in garch_q_values:\n",
    "                print(f\"\\nTraining model with seq_length={seq_length}, forecast_horizon={forecast_horizon}, p={p}, q={q}\")\n",
    "                \n",
    "                # Initialize model\n",
    "                model = HybridModel(\n",
    "                    seq_length=seq_length,\n",
    "                    forecast_horizon=forecast_horizon,\n",
    "                    p=p,\n",
    "                    q=q,\n",
    "                    mean='Zero',\n",
    "                    vol='GARCH',\n",
    "                    dist='normal'\n",
    "                )\n",
    "                \n",
    "                # Train model\n",
    "                model.fit(\n",
    "                    price_data=train_price,\n",
    "                    weather_data=train_features,\n",
    "                    nn_epochs=20,  # Reduced for quicker comparison\n",
    "                    nn_batch_size=32,\n",
    "                    nn_validation_split=0.2,\n",
    "                    verbose=0\n",
    "                )\n",
    "                \n",
    "                # Make predictions\n",
    "                forecasts = model.predict(\n",
    "                    price_data=test_price,\n",
    "                    weather_data=test_features,\n",
    "                    confidence_level=0.95\n",
    "                )\n",
    "                \n",
    "                # Calculate metrics\n",
    "                actual = test_price['price']\n",
    "                predicted = forecasts['price_forecast']\n",
    "                \n",
    "                mse = mean_squared_error(actual, predicted)\n",
    "                rmse = np.sqrt(mse)\n",
    "                mae = mean_absolute_error(actual, predicted)\n",
    "                mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "                r2 = r2_score(actual, predicted)\n",
    "                \n",
    "                # Calculate confidence interval coverage\n",
    "                lower_bound = forecasts['lower_bound']\n",
    "                upper_bound = forecasts['upper_bound']\n",
    "                within_bounds = ((actual >= lower_bound) & (actual <= upper_bound))\n",
    "                coverage = within_bounds.mean() * 100\n",
    "                \n",
    "                # Store results\n",
    "                results.append({\n",
    "                    'seq_length': seq_length,\n",
    "                    'forecast_horizon': forecast_horizon,\n",
    "                    'garch_p': p,\n",
    "                    'garch_q': q,\n",
    "                    'MSE': mse,\n",
    "                    'RMSE': rmse,\n",
    "                    'MAE': mae,\n",
    "                    'MAPE': mape,\n",
    "                    'R2': r2,\n",
    "                    'CI_Coverage': coverage\n",
    "                })\n",
    "                \n",
    "                print(f\"  RMSE: {rmse:.2f}, MAE: {mae:.2f}, MAPE: {mape:.2f}%, R2: {r2:.4f}, CI Coverage: {coverage:.2f}%\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel comparison results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc24201-a992-43c8-8aae-1a9f03793216",
   "metadata": {},
   "source": [
    "## Visualizing Model Comparison Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacfe521-9fee-44f4-9c8c-1d4b3ddbf5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RMSE by hyperparameters\n",
    "fig = px.scatter(\n",
    "    results_df,\n",
    "    x='seq_length',\n",
    "    y='RMSE',\n",
    "    size='forecast_horizon',\n",
    "    color='garch_p',\n",
    "    symbol='garch_q',\n",
    "    title='Model Performance Comparison (RMSE)',\n",
    "    labels={'seq_length': 'Sequence Length (hours)', 'RMSE': 'Root Mean Squared Error'},\n",
    "    height=500,\n",
    "    width=800\n",
    ")\n",
    "fig.update_layout(template='plotly_white')\n",
    "fig.show()\n",
    "\n",
    "# Plot MAPE by hyperparameters\n",
    "fig = px.scatter(\n",
    "    results_df,\n",
    "    x='seq_length',\n",
    "    y='MAPE',\n",
    "    size='forecast_horizon',\n",
    "    color='garch_p',\n",
    "    symbol='garch_q',\n",
    "    title='Model Performance Comparison (MAPE)',\n",
    "    labels={'seq_length': 'Sequence Length (hours)', 'MAPE': 'Mean Absolute Percentage Error (%)'},\n",
    "    height=500,\n",
    "    width=800\n",
    ")\n",
    "fig.update_layout(template='plotly_white')\n",
    "fig.show()\n",
    "\n",
    "# Plot CI Coverage by hyperparameters\n",
    "fig = px.scatter(\n",
    "    results_df,\n",
    "    x='seq_length',\n",
    "    y='CI_Coverage',\n",
    "    size='forecast_horizon',\n",
    "    color='garch_p',\n",
    "    symbol='garch_q',\n",
    "    title='Confidence Interval Coverage Comparison',\n",
    "    labels={'seq_length': 'Sequence Length (hours)', 'CI_Coverage': 'CI Coverage (%)'},\n",
    "    height=500,\n",
    "    width=800\n",
    ")\n",
    "fig.update_layout(\n",
    "    template='plotly_white',\n",
    "    yaxis=dict(range=[80, 100])  # Focus on the relevant range for coverage\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1eaa1a-9425-4e10-9f84-de9f9e107a00",
   "metadata": {},
   "source": [
    "## Finding the Best Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4a19d-e9eb-4f9a-a148-bd51fb81542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the model with lowest RMSE\n",
    "best_rmse_idx = results_df['RMSE'].idxmin()\n",
    "best_rmse_model = results_df.iloc[best_rmse_idx]\n",
    "print(\"\\nBest model by RMSE:\")\n",
    "print(best_rmse_model)\n",
    "\n",
    "# Find the model with lowest MAPE\n",
    "best_mape_idx = results_df['MAPE'].idxmin()\n",
    "best_mape_model = results_df.iloc[best_mape_idx]\n",
    "print(\"\\nBest model by MAPE:\")\n",
    "print(best_mape_model)\n",
    "\n",
    "# Find the model with best confidence interval coverage\n",
    "# (closest to the expected 95%)\n",
    "results_df['CI_Coverage_Error'] = abs(results_df['CI_Coverage'] - 95)\n",
    "best_coverage_idx = results_df['CI_Coverage_Error'].idxmin()\n",
    "best_coverage_model = results_df.iloc[best_coverage_idx]\n",
    "print(\"\\nBest model by confidence interval coverage:\")\n",
    "print(best_coverage_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a93051e-30d6-4186-8e87-5811ed0d0783",
   "metadata": {},
   "source": [
    "## Train and Visualize Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337b179a-2939-40d1-8a0d-cddc2ba2620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best RMSE model configuration\n",
    "best_seq_length = int(best_rmse_model['seq_length'])\n",
    "best_forecast_horizon = int(best_rmse_model['forecast_horizon'])\n",
    "best_p = int(best_rmse_model['garch_p'])\n",
    "best_q = int(best_rmse_model['garch_q'])\n",
    "\n",
    "print(f\"Training final model with best configuration: seq_length={best_seq_length}, forecast_horizon={best_forecast_horizon}, p={best_p}, q={best_q}\")\n",
    "\n",
    "# Initialize and train best model\n",
    "best_model = HybridModel(\n",
    "    seq_length=best_seq_length,\n",
    "    forecast_horizon=best_forecast_horizon,\n",
    "    p=best_p,\n",
    "    q=best_q,\n",
    "    mean='Zero',\n",
    "    vol='GARCH',\n",
    "    dist='normal'\n",
    ")\n",
    "\n",
    "best_model.fit(\n",
    "    price_data=train_price,\n",
    "    weather_data=train_features,\n",
    "    nn_epochs=50,  # More epochs for final model\n",
    "    nn_batch_size=32,\n",
    "    nn_validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Generate forecasts\n",
    "best_forecasts = best_model.predict(\n",
    "    price_data=test_price,\n",
    "    weather_data=test_features,\n",
    "    confidence_level=0.95\n",
    ")\n",
    "\n",
    "# Plot final forecasts\n",
    "fig_final = plot_price_forecast(\n",
    "    forecasts=best_forecasts,\n",
    "    historical_data=test_price,\n",
    "    title=f\"Best Model: ERCOT Houston Hub Price Forecast (seq={best_seq_length}, horizon={best_forecast_horizon}, GARCH({best_p},{best_q}))\"\n",
    ")\n",
    "fig_final.show()\n",
    "\n",
    "# Plot model performance\n",
    "fig_performance = plot_model_performance(\n",
    "    actual_prices=test_price['price'],\n",
    "    forecasted_prices=best_forecasts['price_forecast'],\n",
    "    train_test_split_date=test_start_date,\n",
    "    title=\"Best Model Performance\"\n",
    ")\n",
    "fig_performance.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f8bed2-f1c0-4bde-8cd7-b0e77ab7fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multi-Step Forecast Evaluation\n",
    "\n",
    "Let's analyze how model performance changes as we forecast further into the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66df72ee-1643-495d-818f-dfe983b250f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract multi-step forecasts for analysis\n",
    "# We'll compare 1, 6, 12, and 24 hours ahead\n",
    "\n",
    "# Use the best model to make a new set of forecasts\n",
    "# for analysis of forecast horizons\n",
    "horizon_forecasts = best_model.predict(\n",
    "    price_data=test_price,\n",
    "    weather_data=test_features,\n",
    "    confidence_level=0.95\n",
    ")\n",
    "\n",
    "# Create DataFrame to store actual and forecasted values at different horizons\n",
    "horizons_to_evaluate = [1, 6, 12, min(24, best_forecast_horizon)]\n",
    "forecast_comparison = pd.DataFrame({'actual': test_price['price']})\n",
    "\n",
    "# Extract forecasts at different horizons\n",
    "for h in horizons_to_evaluate:\n",
    "    if h <= best_forecast_horizon:\n",
    "        horizon_col = f'h{h}'\n",
    "        # Offset the forecast by h-1 steps to align with actuals\n",
    "        forecast_comparison[horizon_col] = horizon_forecasts['price_forecast'].shift(-(h-1))\n",
    "\n",
    "# Drop NaN values\n",
    "forecast_comparison = forecast_comparison.dropna()\n",
    "\n",
    "# Calculate metrics for each horizon\n",
    "horizon_results = []\n",
    "for h in horizons_to_evaluate:\n",
    "    if h <= best_forecast_horizon:\n",
    "        horizon_col = f'h{h}'\n",
    "        h_mse = mean_squared_error(forecast_comparison['actual'], forecast_comparison[horizon_col])\n",
    "        h_rmse = np.sqrt(h_mse)\n",
    "        h_mae = mean_absolute_error(forecast_comparison['actual'], forecast_comparison[horizon_col])\n",
    "        h_mape = np.mean(np.abs((forecast_comparison['actual'] - forecast_comparison[horizon_col]) / forecast_comparison['actual'])) * 100\n",
    "        \n",
    "        horizon_results.append({\n",
    "            'Horizon (hours)': h,\n",
    "            'RMSE': h_rmse,\n",
    "            'MAE': h_mae,\n",
    "            'MAPE': h_mape\n",
    "        })\n",
    "\n",
    "# Create DataFrame with horizon results\n",
    "horizon_results_df = pd.DataFrame(horizon_results)\n",
    "print(\"\\nForecast error by horizon:\")\n",
    "print(horizon_results_df)\n",
    "\n",
    "# Plot metrics by horizon\n",
    "metrics = ['RMSE', 'MAE', 'MAPE']\n",
    "for metric in metrics:\n",
    "    fig = px.line(\n",
    "        horizon_results_df,\n",
    "        x='Horizon (hours)',\n",
    "        y=metric,\n",
    "        markers=True,\n",
    "        title=f'{metric} by Forecast Horizon',\n",
    "        height=400,\n",
    "        width=700\n",
    "    )\n",
    "    fig.update_layout(template='plotly_white')\n",
    "    fig.show()\n",
    "\n",
    "# Plot multi-horizon forecasts\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add actual prices\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=forecast_comparison.index[-48:],  # Last 48 hours\n",
    "    y=forecast_comparison['actual'][-48:],\n",
    "    mode='lines',\n",
    "    name='Actual Price',\n",
    "    line=dict(color='black', width=2)\n",
    "))\n",
    "\n",
    "# Add forecasts at different horizons\n",
    "colors = ['blue', 'green', 'orange', 'red']\n",
    "for i, h in enumerate(horizons_to_evaluate):\n",
    "    if h <= best_forecast_horizon:\n",
    "        horizon_col = f'h{h}'\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=forecast_comparison.index[-48:],\n",
    "            y=forecast_comparison[horizon_col][-48:],\n",
    "            mode='lines',\n",
    "            name=f'{h}-hour ahead',\n",
    "            line=dict(color=colors[i % len(colors)])\n",
    "        ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Price Forecasts at Different Horizons (Last 48 Hours)',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Price ($/MWh)',\n",
    "    height=500,\n",
    "    width=900,\n",
    "    template='plotly_white',\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be01bcbe-8e51-462f-a9fd-5e76648b7746",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this script, we've performed an extensive analysis of features that impact ERCOT electricity prices and compared different model configurations. Key findings:\n",
    "\n",
    "1. Feature importance analysis identified the most predictive variables for price forecasting\n",
    "2. We observed clear price patterns by time of day, day of week, and season\n",
    "3. Weather variables showed significant correlations with electricity prices\n",
    "4. Model hyperparameter tuning found the optimal configuration for our hybrid model\n",
    "5. Performance evaluation across different forecast horizons showed how accuracy degrades with longer horizons\n",
    "\n",
    "These insights help us better understand the drivers of ERCOT prices and how to optimize our forecasting approach. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
