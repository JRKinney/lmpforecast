{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERCOT Price Forecasting Model Building and Visualization Demo\n",
    "\n",
    "This script demonstrates how to build, train, and evaluate the hybrid forecasting model\n",
    "for ERCOT electricity prices, and how to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple, Optional, Union, Any\n",
    "\n",
    "# Add the project directory to the path so we can import modules\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('ggplot')\n",
    "# %matplotlib inline\n",
    "\n",
    "# Import our modules\n",
    "from src.data.ercot_price_data import ErcotPriceData\n",
    "from src.data.ercot_weather_data import ErcotWeatherData\n",
    "from src.models.hybrid_model import HybridModel\n",
    "from src.utils.preprocessing import (\n",
    "    align_time_series,\n",
    "    create_time_features,\n",
    "    create_lag_features,\n",
    "    create_rolling_features,\n",
    "    prepare_data_for_model\n",
    ")\n",
    "from src.visualization.plotting import (\n",
    "    plot_price_forecast,\n",
    "    plot_volatility_forecast,\n",
    "    plot_price_components,\n",
    "    plot_model_performance\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation\n",
    "\n",
    "First, let's load the price and weather data for the Houston hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date range for our analysis\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=365)  # Use one year of data\n",
    "test_start_date = end_date - timedelta(days=30)  # Last 30 days for testing\n",
    "\n",
    "# Load price data\n",
    "price_data = ErcotPriceData().load_data(\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    price_node='HB_HOUSTON',\n",
    "    resample_freq='H'\n",
    ")\n",
    "\n",
    "# Load weather data for Houston\n",
    "weather_data = ErcotWeatherData().load_data(\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    location='Houston',\n",
    "    resample_freq='H'\n",
    ")\n",
    "\n",
    "print(f\"Price data shape: {price_data.shape}\")\n",
    "print(f\"Weather data shape: {weather_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Let's preprocess the data to align the time series and create features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align price and weather data\n",
    "aligned_data = align_time_series(price_data, weather_data)\n",
    "print(f\"Aligned data shape: {aligned_data.shape}\")\n",
    "\n",
    "# Create time features\n",
    "data_with_time_features = create_time_features(aligned_data)\n",
    "print(f\"Data with time features shape: {data_with_time_features.shape}\")\n",
    "print(f\"Columns: {data_with_time_features.columns.tolist()}\")\n",
    "\n",
    "# Create lag features for prices (lag of 1, 24, and 168 hours)\n",
    "data_with_lag_features = create_lag_features(\n",
    "    data_with_time_features, \n",
    "    target_column='price', \n",
    "    lag_periods=[1, 24, 168]\n",
    ")\n",
    "print(f\"Data with lag features shape: {data_with_lag_features.shape}\")\n",
    "\n",
    "# Create rolling features (mean and std) with windows of 24 and 168 hours\n",
    "data_with_rolling_features = create_rolling_features(\n",
    "    data_with_lag_features, \n",
    "    target_column='price',\n",
    "    windows=[24, 168],\n",
    "    functions=['mean', 'std']\n",
    ")\n",
    "print(f\"Data with rolling features shape: {data_with_rolling_features.shape}\")\n",
    "\n",
    "# Drop rows with NaN values (due to lagging)\n",
    "preprocessed_data = data_with_rolling_features.dropna()\n",
    "print(f\"Preprocessed data shape (after dropping NaN): {preprocessed_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "train_data = preprocessed_data[preprocessed_data.index < test_start_date]\n",
    "test_data = preprocessed_data[preprocessed_data.index >= test_start_date]\n",
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Testing data shape: {test_data.shape}\")\n",
    "\n",
    "# Extract price and weather components\n",
    "train_price = train_data[['price']]\n",
    "test_price = test_data[['price']]\n",
    "\n",
    "# Weather and feature columns (excluding price)\n",
    "feature_columns = [col for col in train_data.columns if col != 'price']\n",
    "train_features = train_data[feature_columns]\n",
    "test_features = test_data[feature_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration\n",
    "\n",
    "Now let's configure and train our hybrid model. We'll set up a model with:\n",
    "- 48-hour sequence length\n",
    "- 24-hour forecast horizon\n",
    "- GARCH(1,1) volatility model\n",
    "- Normal error distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters\n",
    "seq_length = 48  # Hours\n",
    "forecast_horizon = 24  # Hours\n",
    "garch_p = 1  # GARCH p parameter\n",
    "garch_q = 1  # GARCH q parameter\n",
    "mean_model = 'Zero'  # Mean model type for GARCH\n",
    "vol_model = 'GARCH'  # Volatility model type\n",
    "dist_model = 'normal'  # Error distribution\n",
    "\n",
    "# Initialize the hybrid model\n",
    "model = HybridModel(\n",
    "    seq_length=seq_length,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    p=garch_p,\n",
    "    q=garch_q,\n",
    "    mean=mean_model,\n",
    "    vol=vol_model,\n",
    "    dist=dist_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Let's train the hybrid model on our training data. This will train both the neural network for price forecasting and the GARCH model for volatility forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Training the hybrid model...\")\n",
    "model.fit(\n",
    "    price_data=train_price,\n",
    "    weather_data=train_features,\n",
    "    nn_epochs=50,\n",
    "    nn_batch_size=32,\n",
    "    nn_validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"Model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "\n",
    "Now let's use our trained model to make predictions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for the test period\n",
    "print(\"Generating forecasts...\")\n",
    "forecasts = model.predict(\n",
    "    price_data=test_price,\n",
    "    weather_data=test_features,\n",
    "    confidence_level=0.95\n",
    ")\n",
    "\n",
    "print(f\"Forecast shape: {forecasts.shape}\")\n",
    "print(f\"Forecast columns: {forecasts.columns.tolist()}\")\n",
    "forecasts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Price Forecasts\n",
    "\n",
    "Let's visualize the price forecasts compared to the actual prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot price forecasts\n",
    "fig_price = plot_price_forecast(\n",
    "    forecasts=forecasts,\n",
    "    historical_data=test_price,\n",
    "    title=\"ERCOT Houston Hub Price Forecast (24-hour horizon)\"\n",
    ")\n",
    "fig_price.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Volatility Forecasts\n",
    "\n",
    "Now let's visualize the volatility forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate historical volatility (rolling standard deviation)\n",
    "historical_volatility = test_price['price'].rolling(window=24).std().dropna()\n",
    "\n",
    "# Extract variance forecasts from the model's output\n",
    "variance_forecast = forecasts[['variance_forecast']]\n",
    "\n",
    "# Plot volatility forecasts\n",
    "fig_vol = plot_volatility_forecast(\n",
    "    variance_forecast=variance_forecast,\n",
    "    historical_volatility=historical_volatility,\n",
    "    title=\"ERCOT Houston Hub Volatility Forecast\"\n",
    ")\n",
    "fig_vol.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Price Components\n",
    "\n",
    "Let's visualize the components that influence the price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot price components (last 7 days of testing data)\n",
    "lookback_period = 168  # 7 days in hours\n",
    "last_week_index = test_price.index[-lookback_period:]\n",
    "last_week_price = test_price.loc[last_week_index]\n",
    "last_week_features = test_features.loc[last_week_index]\n",
    "\n",
    "fig_components = plot_price_components(\n",
    "    price_data=last_week_price,\n",
    "    weather_data=last_week_features,\n",
    "    lookback_window=lookback_period,\n",
    "    forecast_window=forecast_horizon,\n",
    "    title=\"ERCOT Houston Hub Price Components\"\n",
    ")\n",
    "fig_components.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance\n",
    "\n",
    "Let's evaluate our model's performance by comparing forecasted prices to actual prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract actual and forecasted prices\n",
    "actual_prices = test_price['price']\n",
    "forecasted_prices = forecasts['price_forecast']\n",
    "\n",
    "# Calculate error metrics\n",
    "forecast_errors = actual_prices - forecasted_prices\n",
    "mse = np.mean(forecast_errors ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = np.mean(np.abs(forecast_errors))\n",
    "mape = np.mean(np.abs(forecast_errors / actual_prices)) * 100  # in percentage\n",
    "\n",
    "print(f\"Model Performance Metrics:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Plot model performance\n",
    "fig_performance = plot_model_performance(\n",
    "    actual_prices=actual_prices,\n",
    "    forecasted_prices=forecasted_prices,\n",
    "    train_test_split_date=test_start_date,\n",
    "    title=\"ERCOT Houston Hub Forecast Performance\"\n",
    ")\n",
    "fig_performance.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Forecast Errors\n",
    "\n",
    "Let's analyze the distribution of forecast errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of forecast errors\n",
    "fig_errors = go.Figure()\n",
    "\n",
    "fig_errors.add_trace(go.Histogram(\n",
    "    x=forecast_errors,\n",
    "    nbinsx=30,\n",
    "    marker_color='blue',\n",
    "    opacity=0.7\n",
    "))\n",
    "\n",
    "# Add a normal distribution curve for reference\n",
    "x_range = np.linspace(forecast_errors.min(), forecast_errors.max(), 100)\n",
    "mean_error = forecast_errors.mean()\n",
    "std_error = forecast_errors.std()\n",
    "y_norm = (1 / (std_error * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x_range - mean_error) / std_error) ** 2)\n",
    "y_norm = y_norm * (forecast_errors.count() * (forecast_errors.max() - forecast_errors.min()) / 30)\n",
    "\n",
    "fig_errors.add_trace(go.Scatter(\n",
    "    x=x_range,\n",
    "    y=y_norm,\n",
    "    mode='lines',\n",
    "    name='Normal Distribution',\n",
    "    line=dict(color='red', dash='dash')\n",
    "))\n",
    "\n",
    "fig_errors.update_layout(\n",
    "    title='Distribution of Forecast Errors',\n",
    "    xaxis_title='Forecast Error ($/MWh)',\n",
    "    yaxis_title='Frequency',\n",
    "    template='plotly_white',\n",
    "    height=500,\n",
    "    width=800\n",
    ")\n",
    "\n",
    "fig_errors.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals\n",
    "\n",
    "Let's analyze the reliability of our model's confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how often the actual price falls within the confidence interval\n",
    "lower_bound = forecasts['lower_bound']\n",
    "upper_bound = forecasts['upper_bound']\n",
    "within_bounds = ((actual_prices >= lower_bound) & (actual_prices <= upper_bound))\n",
    "coverage_rate = within_bounds.mean() * 100\n",
    "\n",
    "print(f\"Confidence Interval Coverage: {coverage_rate:.2f}%\")\n",
    "print(f\"Expected Coverage (95% confidence): 95.00%\")\n",
    "\n",
    "# Create a dataframe for plotting confidence intervals\n",
    "ci_data = pd.DataFrame({\n",
    "    'actual': actual_prices,\n",
    "    'forecast': forecasted_prices,\n",
    "    'lower_bound': lower_bound,\n",
    "    'upper_bound': upper_bound\n",
    "})\n",
    "\n",
    "# Plot a sample of the confidence intervals (last 7 days)\n",
    "last_7_days = ci_data.iloc[-168:]  # Last 7 days (168 hours)\n",
    "\n",
    "fig_ci = go.Figure()\n",
    "\n",
    "# Add actual price trace\n",
    "fig_ci.add_trace(go.Scatter(\n",
    "    x=last_7_days.index,\n",
    "    y=last_7_days['actual'],\n",
    "    mode='lines',\n",
    "    name='Actual Price',\n",
    "    line=dict(color='black', width=2)\n",
    "))\n",
    "\n",
    "# Add forecast price trace\n",
    "fig_ci.add_trace(go.Scatter(\n",
    "    x=last_7_days.index,\n",
    "    y=last_7_days['forecast'],\n",
    "    mode='lines',\n",
    "    name='Forecasted Price',\n",
    "    line=dict(color='blue', width=2)\n",
    "))\n",
    "\n",
    "# Add confidence interval\n",
    "fig_ci.add_trace(go.Scatter(\n",
    "    x=last_7_days.index.tolist() + last_7_days.index.tolist()[::-1],\n",
    "    y=last_7_days['upper_bound'].tolist() + last_7_days['lower_bound'].tolist()[::-1],\n",
    "    fill='toself',\n",
    "    fillcolor='rgba(0, 176, 246, 0.2)',\n",
    "    line=dict(color='rgba(255, 255, 255, 0)'),\n",
    "    name='95% Confidence Interval'\n",
    "))\n",
    "\n",
    "fig_ci.update_layout(\n",
    "    title='Price Forecast with 95% Confidence Interval (Last 7 Days)',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Price ($/MWh)',\n",
    "    template='plotly_white',\n",
    "    height=600,\n",
    "    width=1000,\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)\n",
    ")\n",
    "\n",
    "fig_ci.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading the Model\n",
    "\n",
    "Let's demonstrate how to save and load the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to save the model if it doesn't exist\n",
    "os.makedirs('../models/saved', exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model_path = '../models/saved/hybrid_model_houston'\n",
    "model.save_models(model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# Load the model\n",
    "loaded_model = HybridModel(\n",
    "    seq_length=seq_length,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    p=garch_p,\n",
    "    q=garch_q,\n",
    "    mean=mean_model,\n",
    "    vol=vol_model,\n",
    "    dist=dist_model\n",
    ")\n",
    "loaded_model.load_models(model_path)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this script, we've demonstrated the complete workflow for building, training, and evaluating a hybrid forecasting model for ERCOT electricity prices:\n",
    "\n",
    "1. Loading and preprocessing price and weather data\n",
    "2. Configuring and training the hybrid model\n",
    "3. Making price and volatility forecasts\n",
    "4. Visualizing the results using various plots\n",
    "5. Evaluating model performance with multiple metrics\n",
    "6. Saving and loading the trained model\n",
    "\n",
    "The hybrid model combines the strengths of neural networks for capturing complex patterns in the price series and GARCH models for modeling volatility, providing accurate forecasts with uncertainty estimates. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
